{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jira Analysis\n",
    "\n",
    "This notebook contains scripts to process a set of tickets dumped from Jira using a LangChain chain and Pinecone."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "I hate having imports strewn all over the code and so, I'm creating a section where I'll keep adding imports.\n",
    "\n",
    "I recognize that this requires me to do a \"Run All\" in the Notebook each time, but it's better that than import hell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "from uuid import uuid4\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv(\"jira_csv.csv\")\n",
    "\n",
    "# Let's make sure we don't have an empty description\n",
    "df.Description = df.Description.fillna(\"No Description Available\")\n",
    "df.Resolved = df.Resolved.fillna(\"0\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From Andre:\\n\\nApp: [https://app.crowdbotics.com/dashboard/app/39571|https://app.crowdbotics.com/dashboard/app/39571]\\nI created a Connector to test OpenAPI response and as it’s an authenticated request, I added the Bearer Token. It looks like an EnvVar was added to the api.js file but when trying to deploy, it failed (stack trace is the first message in the app Activity Log) because of the newly added token.\\n\\nIssue with react-native-dotenv: [https://app.circleci.com/pipelines/github/crowdbotics-apps/andre-test-mar-27-39571/4/workflows/c8bdd4fc-a811-4993-afe7-7a610591a870/jobs/12|https://app.circleci.com/pipelines/github/crowdbotics-apps/andre-test-mar-27-39571/4/workflows/c8bdd4fc-a811-4993-afe7-7a610591a870/jobs/12]\\n\\n\\nAnother issue is regarding the connector code generated in GitHub. When I first added the connector, and it has a token, the token was correctly added to the openAPI store, but after changing the connector detail to add a few more fields to the response and save, the token was removed from the code. I had to go back to the connector and add the token again and save, then it was added back to the connector’s store.\\n\\n----\\n\\nSteps to test and reproduce\\n\\n# Go to Connectors page\\n# Create a connector with Bearer auth (can be fake information)\\n# Save\\n# Check if env var is added to the connector code like this: [https://github.com/crowdbotics-dev/aline-032923-dev-73007/blob/323de66db33c0ccd349eb64c10a0bf33958c89cc/store/rapidAPICocktails/api.js#L8|https://github.com/crowdbotics-dev/aline-032923-dev-73007/blob/323de66db33c0ccd349eb64c10a0bf33958c89cc/store/rapidAPICocktails/api.js#L8|smart-link] \\n# Go to \"Active in my project\" tab\\n# Edit the connector (like the description or new data call) - but do not edit the auth token. Save\\n# Expect the Bearer header to still exist in the connector generated code.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Description\n",
       "3  From Andre:\\n\\nApp: [https://app.crowdbotics.com/dashboard/app/39571|https://app.crowdbotics.com/dashboard/app/39571]\\nI created a Connector to test OpenAPI response and as it’s an authenticated request, I added the Bearer Token. It looks like an EnvVar was added to the api.js file but when trying to deploy, it failed (stack trace is the first message in the app Activity Log) because of the newly added token.\\n\\nIssue with react-native-dotenv: [https://app.circleci.com/pipelines/github/crowdbotics-apps/andre-test-mar-27-39571/4/workflows/c8bdd4fc-a811-4993-afe7-7a610591a870/jobs/12|https://app.circleci.com/pipelines/github/crowdbotics-apps/andre-test-mar-27-39571/4/workflows/c8bdd4fc-a811-4993-afe7-7a610591a870/jobs/12]\\n\\n\\nAnother issue is regarding the connector code generated in GitHub. When I first added the connector, and it has a token, the token was correctly added to the openAPI store, but after changing the connector detail to add a few more fields to the response and save, the token was removed from the code. I had to go back to the connector and add the token again and save, then it was added back to the connector’s store.\\n\\n----\\n\\nSteps to test and reproduce\\n\\n# Go to Connectors page\\n# Create a connector with Bearer auth (can be fake information)\\n# Save\\n# Check if env var is added to the connector code like this: [https://github.com/crowdbotics-dev/aline-032923-dev-73007/blob/323de66db33c0ccd349eb64c10a0bf33958c89cc/store/rapidAPICocktails/api.js#L8|https://github.com/crowdbotics-dev/aline-032923-dev-73007/blob/323de66db33c0ccd349eb64c10a0bf33958c89cc/store/rapidAPICocktails/api.js#L8|smart-link] \\n# Go to \"Active in my project\" tab\\n# Edit the connector (like the description or new data call) - but do not edit the auth token. Save\\n# Expect the Bearer header to still exist in the connector generated code."
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_col = df.columns.get_loc('Description')\n",
    "\n",
    "# I use the 4th record in the list because it has a really long description.\n",
    "df.iloc[[3],[desc_col]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk the data\n",
    "\n",
    "In our case, we will only chunk up the `Description` field from Jira."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    '''\n",
    "    Creates tokens from input text and returns the number of tokens.\n",
    "\n",
    "        Parameters:\n",
    "            text (str): The text to be tokenized\n",
    "        \n",
    "        Returns:\n",
    "            The number of tokens created from the text (int)\n",
    "    '''\n",
    "    tokens = tokenizer.encode(text, disallowed_special=())\n",
    "    return len(tokens)\n",
    "\n",
    "print(tiktoken_len(str(df.iloc[[3],[desc_col]])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a way of finding the number of tokens, let us initialize a splitter that uses the `tiktoken_len` function that we just created to split input text so that each chunk is never larger than a maximum that we set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=20,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us initialize the OpenAI API and create a test embedding just so we know everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1536)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or 'OPENAI_API_KEY'\n",
    "\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "###### TEST TO MAKE SURE OPENAI API KEY WORKS\n",
    "texts = [\n",
    "    'this is the first chunk of text',\n",
    "    'then another second chunk of text is here'\n",
    "]\n",
    "\n",
    "res = embed.embed_documents(texts)\n",
    "len(res), len(res[0])\n",
    "###### END TEST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to create and initialize our vector database using Pinecone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 1001}},\n",
       " 'total_vector_count': 1001}"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"gpt-test\"\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\") or \"PINECONE_API_KEY\"\n",
    "PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\") or \"PINECONE_ENVIRONMENT\"\n",
    "\n",
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # we create a new index\n",
    "    pinecone.create_index(\n",
    "        name=index_name,\n",
    "        metric='cosine',\n",
    "        dimension=len(res[0])  # 1536 dim of text-embedding-ada-002\n",
    "    )\n",
    "\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1836\n",
      "2\n",
      "Chunk 0 307 From Andre:\n",
      "\n",
      "App: [https://app.crowdbotics.com/dashboard/app/39571|https://app.crowdbotics.com/dashboard/app/39571]\n",
      "I created a Connector to test OpenAPI response and as it’s an authenticated request, I added the Bearer Token. It looks like an EnvVar was added to the api.js file but when trying to deploy, it failed (stack trace is the first message in the app Activity Log) because of the newly added token.\n",
      "\n",
      "Issue with react-native-dotenv: [https://app.circleci.com/pipelines/github/crowdbotics-apps/andre-test-mar-27-39571/4/workflows/c8bdd4fc-a811-4993-afe7-7a610591a870/jobs/12|https://app.circleci.com/pipelines/github/crowdbotics-apps/andre-test-mar-27-39571/4/workflows/c8bdd4fc-a811-4993-afe7-7a610591a870/jobs/12]\n",
      "\n",
      "\n",
      "Another issue is regarding the connector code generated in GitHub. When I first added the connector, and it has a token, the token was correctly added to the openAPI store, but after changing the connector detail to add a few more fields to the response and save, the token was removed from the code. I had to go back to the connector and add the token again and save, then it was added back to the connector’s store.\n",
      "\n",
      "----\n",
      "\n",
      "Steps to test and reproduce\n",
      "Chunk 1 208 ----\n",
      "\n",
      "Steps to test and reproduce\n",
      "\n",
      "# Go to Connectors page\n",
      "# Create a connector with Bearer auth (can be fake information)\n",
      "# Save\n",
      "# Check if env var is added to the connector code like this: [https://github.com/crowdbotics-dev/aline-032923-dev-73007/blob/323de66db33c0ccd349eb64c10a0bf33958c89cc/store/rapidAPICocktails/api.js#L8|https://github.com/crowdbotics-dev/aline-032923-dev-73007/blob/323de66db33c0ccd349eb64c10a0bf33958c89cc/store/rapidAPICocktails/api.js#L8|smart-link] \n",
      "# Go to \"Active in my project\" tab\n",
      "# Edit the connector (like the description or new data call) - but do not edit the auth token. Save\n",
      "# Expect the Bearer header to still exist in the connector generated code.\n"
     ]
    }
   ],
   "source": [
    "test_row = df.iloc[3]\n",
    "metadata = {\n",
    "    \"id\": test_row[\"Issue key\"],\n",
    "    \"type\": test_row[\"Issue Type\"],\n",
    "    \"status\": test_row[\"Status\"],\n",
    "    \"summary\": test_row[\"Summary\"],\n",
    "    \"created\": test_row[\"Created\"],\n",
    "    \"resolved\": test_row[\"Resolved\"]\n",
    "}\n",
    "\n",
    "print(len(test_row['Description']))\n",
    "\n",
    "test_row_chunks = text_splitter.split_text(test_row['Description'])\n",
    "\n",
    "print(len(test_row_chunks))\n",
    "for i, desc in enumerate(test_row_chunks):\n",
    "    print(\"Chunk\", i, tiktoken_len(desc), desc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (RUN WITH CAUTION) Create Embeddings\n",
    "\n",
    "This embeddings insert into the vector is currently not idempotent. So, it will create duplicate records in the vector. Do NOT run this unless you intend to create duplicates as I ended up doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20683407fc864ada99b99f9097724040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100\n",
      "100 100 100 100\n",
      "100 100 100 100\n",
      "100 100 100 100\n",
      "100 100 100 100\n",
      "100 100 100 100\n",
      "100 100 100 100\n",
      "100 100 100 100\n",
      "101 101 101 101\n",
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "batch_limit = 100\n",
    "\n",
    "descriptions = [] # list to store chunked descriptions\n",
    "metadata_list = []\n",
    "\n",
    "data_list = df.to_dict(\"records\")   # converts df to list of dicts\n",
    "                                    # Makes it easier to iterate.\n",
    "\n",
    "for i,row in enumerate(tqdm(data_list)):\n",
    "    metadata = {\n",
    "        \"id\": row[\"Issue key\"],\n",
    "        \"type\": row[\"Issue Type\"],\n",
    "        \"status\": row[\"Status\"],\n",
    "        \"summary\": row[\"Summary\"],\n",
    "        \"created\": row[\"Created\"],\n",
    "        \"resolved\": row[\"Resolved\"]\n",
    "    }\n",
    "\n",
    "    # Create chunks for description of each row\n",
    "    row_chunks = text_splitter.split_text(row['Description'])\n",
    "    # Create metadata for each chunk\n",
    "    metadata_chunks = [{\n",
    "        \"chunk\": j, \"description\": description, **metadata\n",
    "    } for j, description in enumerate(row_chunks)]\n",
    "    descriptions.extend(row_chunks)\n",
    "    metadata_list.extend(metadata_chunks)\n",
    "    # Loop until you've reached the batch limit\n",
    "    if len(descriptions) >= batch_limit:\n",
    "        ids = [str(uuid4()) for _ in range(len(descriptions))]\n",
    "        embeds = embed.embed_documents(descriptions)\n",
    "        print(len(ids), len(descriptions), len(metadata_list), len(embeds))\n",
    "        upsert_vectors = list(zip(ids, embeds, metadata_list))\n",
    "        index.upsert(vectors=upsert_vectors)\n",
    "        descriptions = []\n",
    "        metadata_list = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_field = \"description\"\n",
    "\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "vectorstore = Pinecone(index, embed.embed_query, desc_field)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Any new tickets to improve the model builder (a.k.a Data Models) as a feature\\n\\nReference → [https://docs.google.com/spreadsheets/d/148Pqr4Jtk86L5yYyEVJqx17gLXNtc6Xwg70toq_cU-U/edit?usp=sharing|https://docs.google.com/spreadsheets/d/148Pqr4Jtk86L5yYyEVJqx17gLXNtc6Xwg70toq_cU-U/edit?usp=sharing|smart-link]', metadata={'chunk': 0.0, 'created': datetime.datetime(2023, 1, 26, 12, 39), 'id': 'PLAT-10056', 'resolved': '0', 'status': 'To Do', 'summary': 'Model Builder Improvements', 'type': 'Epic'}),\n",
       " Document(page_content='Any new tickets to improve the model builder (a.k.a Data Models) as a feature\\n\\nReference → [https://docs.google.com/spreadsheets/d/148Pqr4Jtk86L5yYyEVJqx17gLXNtc6Xwg70toq_cU-U/edit?usp=sharing|https://docs.google.com/spreadsheets/d/148Pqr4Jtk86L5yYyEVJqx17gLXNtc6Xwg70toq_cU-U/edit?usp=sharing|smart-link]', metadata={'chunk': 0.0, 'created': datetime.datetime(2023, 1, 26, 12, 39), 'id': 'PLAT-10056', 'resolved': '0', 'status': 'To Do', 'summary': 'Model Builder Improvements', 'type': 'Epic'}),\n",
       " Document(page_content='The goal of this ticket is to improve some of the canvas of Studio and make elements  more visually distinct. We have done a similar update before, but there has been a feedback that users struggle to connect screens.\\n\\nTake inspiration from Storyboard. Example: [https://crowdbotics-slack-dev.crowdbotics.com/dashboard/app/23757/storyboard|https://crowdbotics-slack-dev.crowdbotics.com/dashboard/app/23757/storyboard]', metadata={'chunk': 0.0, 'created': datetime.datetime(2023, 1, 24, 10, 44), 'id': 'PLAT-10037', 'resolved': datetime.datetime(2023, 1, 26, 22, 48), 'status': 'Done', 'summary': 'UI Updates to Studio Canvas Connections', 'type': 'Task'}),\n",
       " Document(page_content='The goal of this ticket is to improve some of the canvas of Studio and make elements  more visually distinct. We have done a similar update before, but there has been a feedback that users struggle to connect screens.\\n\\nTake inspiration from Storyboard. Example: [https://crowdbotics-slack-dev.crowdbotics.com/dashboard/app/23757/storyboard|https://crowdbotics-slack-dev.crowdbotics.com/dashboard/app/23757/storyboard]', metadata={'chunk': 0.0, 'created': datetime.datetime(2023, 1, 24, 10, 44), 'id': 'PLAT-10037', 'resolved': datetime.datetime(2023, 1, 26, 22, 48), 'status': 'Done', 'summary': 'UI Updates to Studio Canvas Connections', 'type': 'Task'}),\n",
       " Document(page_content='This is a ticket to capture any small one off UI/UX changes that might not be worth a ticket on it’s own\\n\\n* Ensure cursor pointer css is on the switches and other clickable parts of the app. Reconsider some of the colors (it almost seems like some switches and text are always disabled)\\n* (Code related) Rename the LeftSectionTitle component \\n* Shapes type border radius needs some better tooltip and explanation to the general user\\n* On the component tree, consider some sort of color change and text transformation to highlight exactly where the new component is selected.\\n* Removed unused legacy styling code.\\n* Fixed warning imaged below.\\n* Removed Spacing on the left of layout', metadata={'chunk': 0.0, 'created': datetime.datetime(2023, 2, 9, 13, 0), 'id': 'PLAT-10264', 'resolved': datetime.datetime(2023, 2, 23, 9, 42), 'status': 'Done', 'summary': 'Polishing New and Existing Studio UI', 'type': 'Story'})]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What tickets relate to visual design?\"\n",
    "\n",
    "vectorstore.similarity_search(\n",
    "    query,  # our search query\n",
    "    k=5  # return 3 most relevant docs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, these tickets seem to be related to UI/UX improvements and minor code changes. They are not specifically related to improving the model builder feature.'"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(\"Can you classify these tickets?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jira-analysis-41397-YTsRMCK2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
